import streamlit as st
from PIL import Image
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,classification_report, confusion_matrix

@st.cache_data
def load_image(path):
    return Image.open(path)

def show_presentation(df):
    st.header("Pr√©sentation")
    st.write("TODO : Pr√©sentation du contexte, des enjeux, et du dataset")


def show_dataviz(df):
    st.header("DataViz")
    st.write("TODO : Analyse des donn√©es avec figures")

    # R√©partition des classes
    fig = plt.figure()
    sns.countplot(y = df['Classe'],hue = df['Classe'],legend=False)
    plt.title("R√©partition des classes de d√©fauts",fontsize=14, fontweight='bold')
    plt.xlabel("Nombre d'images")
    plt.ylabel("Classe de d√©faut")
    sns.despine()
    st.pyplot(fig)

def show_method():
    st.header("M√©thodologie")

    st.subheader(f"Machine Learning et Deep Learning")

    # Description des approches
    st.markdown("""
    Quatre approches ont √©t√© exp√©riment√©es :

    - **Approche Machine Learning classique** exploitant des **features *localis√©s*** (ex : pixels bruts...)  
    - **Approche Machine Learning classique** exploitant uniquement des **features *non localis√©s*** (ex : contraste...)  
    - **Approche Deep Learning** exploitant les images avec des r√©seaux de neurones convolutionnels *maison*  
    - **Approche Transfer Learning** exploitant les images avec des mod√®les pr√©-entra√Æn√©s  
    """)

    # Description des features localis√©s
    with st.expander("Pour en savoir plus sur les features localis√©s"):
        st.markdown("""
                    Ces descripteurs conservent une information de position ou de structure dans l'image. Nous avons extrait pour chaque image :
                    - Le **vecteur de pixels bruts** : les images sont d'abord redimensionn√©es (de 60x110 √† 30x55 pixels par exemple), puis leurs pixels sont lin√©aris√©s sous forme de vecteur 1D. Chaque pixel, codant une valeur de temp√©rature (niveau de gris), est alors une feature.
                    - Le **descripteur HOG** (Histogram of Oriented Gradients) : on d√©coupe l'image en cellules et on y calcule des histogrammes d'orientations de gradient, puis on normalise ces histogrammes. Le vecteur HOG r√©sultant capture les formes et structures pr√©sentes dans l'image.
                    """)
        st.image(load_image("resources/features_hog.png"),caption = "Exemples de descripteurs HOG (repr√©sentation 2D) pour quelques images")

    # Description des features non localis√©s
    with st.expander("Pour en savoir plus sur les features non localis√©s"):
        st.markdown("""
                    Ces descripteurs sont calcul√©s sur l'image enti√®re, sans consid√©ration explicite de la position spatiale. Nous avons extrait pour chaque image :
                    - des **statistiques sur les intensit√©s** (niveaux de gris de l'image) : moyenne, m√©diane, minimum, maximum, √©cart-type, quantiles (p5, p10, ‚Ä¶, p95) et histogramme sur 256 bins (0 √† 255).
                    - des **propri√©t√©s extraites de la matrice GLCM** : la Grey Level Co-occurrence Matrix mesure la fr√©quence de co-occurrence de paires de niveaux de gris √† une certaine distance et orientation.
                    On en extrait des propri√©t√©s qui quantifient la texture globale de l'image : contraste, √©nergie... 
                    - des **statistiques sur la carte d'entropie** : moyenne, √©cart-type, histogramme d'entropie, etc. pour caract√©riser la complexit√© de l'image.
                    - la **densit√© de contours** d√©tect√©s dans l'image : pourcentage calcul√© apr√®s application d'un filtre de Canny.
                    - des **statistiques sur les ‚Äúhot spots‚Äù** : ce sont des r√©gions anormalement chaudes dans le panneau. Nous utilisons un seuillage adaptatif pour les d√©tecter et nous en extrayons des statistiques...
                    """)
        st.image(load_image("resources/features_entropy_canny.png"),caption = "Exemples de cartes d'entropie et contours d√©tect√©s pour quelques images")
    
    st.subheader(f"A la recherche du meilleur mod√®le...")

    # Un onglet M√©thodologie ML / Un onglet M√©thodologie DL
    tab1, tab2 = st.tabs(["Approches Machine Learning", "Approches Deep Learning"])
    with tab1:
        st.markdown("""
        Nous avons entra√Æn√© plusieurs **classifieurs** :
        - bas√©s sur les distances (SVM...)
        - bas√©s sur les arbres de d√©cision (Random Forest, XGBoost, LightGBM...)
        - √©galement un r√©seau de neurones dense
                    
        Nous avons mis en oeuvre une **validation crois√©e** avec grille de param√®tres pour optimiser notre pipeline :
        - d√©termination des **meilleures √©tapes de pr√©traitement** : extraction de features, mise √† l'√©chelle, r√©duction de dimensions, r√©√©chantillonnage‚Ä¶  
        - optimisation des **param√®tres internes des √©tapes** (ex. extraction de features : taille des cellules HOG)  
        - optimisation des **hyperparam√®tres des classifieurs** (ex. SVM : param√®tre de r√©gularisation `C`)  
        """)
    with tab2:
        st.markdown("""
        Nous avons test√© un r√©seau de neurones convolutif *maison*, et 2 mod√®les pr√©entra√Æn√©s sur ImageNet : MobileNetV2 et EfficientNetV2B2.
        Pour l'**entra√Ænement**, nous avons utilis√© :
        - la fonction de perte `sparse_categorical_crossentropy` adapt√©e aux probl√®mes multi-classes
        - l'optimiseur Adam pour la descente de gradient.
        - des callbacks pour √©viter le sur-apprentissage (`EarlyStopping` et `ReduceLROnPlateau` en cas de plafonnement des performances).
                    
        Nous avons mis en oeuvre une **validation fixe** avec grille de param√®tres pour optimiser notre r√©seau :
        - activation ou non de **couches d'augmentation de donn√©es** (ex : `RandomFlip`, `RandomContrast`)  
        - recherche d'une configuration optimale pour les **couches d'extraction de features** (ex : nb de filtres de convolution par couche)  
        - recherche d'une configuration optimale pour les **couches de classification** (ex : nb de couches `Dense`)  
        - optimisation de la **profondeur du d√©gel** dans le cas du Transfer Learning  
        """)
    
    # Description des m√©triques
    st.markdown("""
    Voici les principales **m√©triques** observ√©es : 
    - le F1-score macro (moyenne sur les 10 classes) : bon compromis pour √©valuer les performances globales dans un jeu d√©s√©quilibr√©.
    - l'accuracy
    - les temps d'entra√Ænement et de pr√©diction
    - la pr√©cision et le rappel de la classe *healthy* : capacit√© √† distinguer les panneaux sains des panneaux d√©fectueux  
    """)

def show_results(modeles,y_test):
    st.header("R√©sultats")

    st.markdown("""
    Nous pr√©sentons les meilleurs mod√®les obtenus apr√®s optimisation, pour les 4 approches mentionn√©es.
    """)

    # Choix du mod√®le par l'utilisateur  
    modele_name = st.selectbox(
        "Choix du mod√®le",
        list(modeles.keys()),
        format_func=lambda name: f"{modeles[name]['methodo_name']} : mod√®le {name}"
    )

    st.subheader(f"Architecture du mod√®le {modele_name}")

    # Description de l'architecture du mod√®le
    if modele_name == "SVM":
        st.markdown("""
                    Les meilleurs r√©sultats de l'approche ML avec features localis√©s ont √©t√© obtenus avec le classifieur SVM (noyau rbf) apr√®s ces √©tapes de preprocessing :
                    - extraction de features : vecteur de pixels bruts + descripteur HOG + statistiques d'entropie
                    - normalisation Min-Max
                    - r√©duction de dimensions par PCA conservant 90% de la variance
                    """)
    if modele_name == "XGBoost":
        st.markdown("""
                    Les meilleurs r√©sultats de l'approche ML avec features non localis√©s ont √©t√© obtenus avec le classifieur XGBoost apr√®s extraction des features,
                    sans √©tape de preprocessing suppl√©mentaire : statistiques sur les intensit√©s + propri√©t√©s extraites de GLCM + statistiques d'entropie + densit√© de contours
                    """)
    if modele_name == "CNN Perso":
        st.markdown("""
                    Les meilleurs r√©sultats de l'approche Deep Learning ont √©t√© obtenus avec ce r√©seau de neurones :
                    - couches d'augmentation de donn√©es actives : `RandomFlip`, `RandomBrightness`, `RandomContrast` et `GaussianNoise`
                    - normalisation des niveaux de gris par `Rescaling`
                    - 4 blocs convolutionels pour l'extraction de features compos√©s chacun de : `Conv2D` avec activation ReLU, puis `MaxPooling2D` pour r√©duire la taille, et un `Dropout` afin de r√©gulariser 
                    - passage en 1D : simple `Flatten`
                    - pour la classification : 2 couches `Dense` 
                    """)
    if modele_name == "MobileNet":
        st.markdown("""
                    Les meilleurs r√©sultats de l'approche Transfer Learning ont √©t√© obtenus avec un fine-tuning du mod√®le pr√©-entra√Æn√© MobileNetV2 :
                    - couches d'augmentation de donn√©es actives : `RandomFlip`, `RandomBrightness`, `RandomContrast` et `GaussianNoise`
                    - couches d'extraction de features : backbone MobileNet, avec un d√©gel des poids √† partir du 5√®me bloc
                    - passage en 1D par `GlobalAveragePooling2D`
                    - pour la classification : une couche `Dense` puis une r√©gularisation `Dropout`, et une derni√®re couche `Dense`
                    """)

    st.subheader(f"Performances du mod√®le {modele_name}")

    # R√©cup√©ration des pr√©dictions du mod√®le sur le jeu de test
    y_pred = modeles[modele_name]["predicted_data_test"]

    # Affichage c√¥te √† c√¥te des m√©triques principales
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Accuracy", round(accuracy_score(y_test,y_pred), 3))
    with col2:
        st.metric("F1 macro", round(f1_score(y_test,y_pred,average="macro"), 3))
    with col3:
        st.metric("Pr√©cision Healthy", round(precision_score(y_test, y_pred, labels=["healthy panel"],average=None)[0], 3))
    with col4:
        st.metric("Rappel Healthy", round(recall_score(y_test, y_pred, labels=["healthy panel"],average=None)[0], 3))

    # Choix par l'utilisateur entre rapport de classification et matrice de confusion
    display = st.radio('Que souhaitez-vous afficher ?', ('Rapport de classification', 'Matrice de confusion'))

    # Affichage rapport de classification
    if display == 'Rapport de classification':
        report_dict = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report_dict).transpose()
        # M√©triques par classe
        st.table(report_df.iloc[:-3,:].style.format(precision=2))
        # M√©triques globales
        st.table(report_df.iloc[-2:,:].style.format(precision=2))

    # Affichage matrice de confusion
    elif display == 'Matrice de confusion':
        cm = confusion_matrix(y_test, y_pred)
        fig = plt.figure()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
        plt.xlabel("Pr√©dictions")
        plt.ylabel("Vraies classes")
        st.pyplot(fig)
    
    st.subheader(f"Interpr√©tabilit√© du mod√®le {modele_name}")

    # Description de l'interpr√©tabilit√© du mod√®le
    if modele_name == "SVM":
        st.markdown("""
                    Le classifieur SVM, qui repose sur un noyau non lin√©aire et pr√©c√©d√© d'une PCA, n'est pas facilement interpr√©table.
                    Nous avons utilis√© **LIME** qui reste une m√©thode approximative et locale.

                    Dans cet exemple, on note que le mod√®le a bien fait le focus sur la bande de salissure situ√©e en haut pour classifier l'image Bottom Dirt. 
                    """)
        st.image(load_image("resources/interpretabilite_svm.png"),caption="Interpr√©tabilit√© LIME sur une image Bottom Dirt")
    if modele_name == "XGBoost":
        st.markdown("""
                    Nous pouvons faire ici une interpr√©tabilit√© assez directe, √† la fois globale et locale, √† l'aide de :
                    - la simplicit√© relative des features et de la pipeline
                    - l'**importance des features** fournie intrins√®quement par XGBoost
                    - l'utilisation de **SHAP**

                    Par exemple avec SHAP, nous pouvons voir les caract√©ristiques les plus influentes pour la classification :
                    - la valeur max des pixels de l'image. Notamment pour les classes healthy et break (qui doit √™tre peu √©lev√©e pour la premi√®re, tr√®s √©lev√©e pour la seconde)
                    - la densit√© de contours
                    - le degr√© de dissym√©trie de la distribution des niveaux de gris
                    - les propri√©t√©s de texture en g√©n√©ral
                    """)
        st.image(load_image("resources/interpretabilite_xgboost.png"),caption="Interpr√©tabilit√© SHAP globale")
    if modele_name == "CNN Perso":
        st.markdown("""
                    Nous avons appliqu√© la technique de **Grad-CAM** sur les couches de convolution de ce CNN pour visualiser les zones des images les plus d√©terminantes dans la d√©cision.
                    D'apr√®s les exemples d'images √©tudi√©s, le CNN a bien appris √† rep√©rer les zones chaudes, les patterns de salissure en bas, etc., concordant avec l'expertise m√©tier.
                    Nous avons √©galement utilis√© **SHAP** en compl√©ment, qui a confirm√© la coh√©rence des principales zones observ√©es par le mod√®le pour la pr√©diction des d√©fauts.

                    Dans l'exemple ci-dessous, une image pr√©dite Short circuit panel, la Grad-CAM met en √©vidence les cellules avec des grosses variations de temp√©rature d√®s la seconde couche de convolution.
                    """)
        st.image(load_image("resources/interpretabilite_cnn.png"),caption="Grad-CAM appliqu√© aux 4 couches de convolution sur une image Short circuit panel")
    if modele_name == "MobileNet":
        st.markdown("""
                    Nous avons appliqu√© **SHAP** sur les images des diff√©rentes cat√©gories pour comprendre sur quelles r√©gions notre mod√®le se focalise pour telle ou telle pr√©diction.
                    Sur quelques images test, SHAP a pu mettre en √©vidence les zones chaudes ou anormales du panneau comme ayant les valeurs SHAP les plus √©lev√©es pour pr√©dire la classe correspondante.
                    En d'autres termes, le mod√®le MobileNet fine-tun√© utilise bien les hot spots ou motifs de panne attendus.

                    Par exemple sur l'image Hot Cell ci-dessous, on constate que les cellules avec une forte variation locale de temp√©rature √† droite ont bien √©t√© rep√©r√©es.
                    """)
        st.image(load_image("resources/interpretabilite_mobilenet.png"),caption="Interpr√©tabilit√© SHAP sur une image Hot Cell")


def show_demo(modeles,X_test,y_test):
    st.header("D√©mo")

    st.markdown("""
                Choisissez des images de test : vous pouvez afficher tous les types de d√©fauts, ou vous concentrer sur un d√©faut en particulier.

                Remarque : ces images n'ont pas √©t√© utilis√©es lors de l'entra√Ænement des mod√®les.
    """)

    with st.container(border=True):
        # Choix par l'utilisateur d'afficher une image de chaque classe, ou une classe en particulier
        all_classes = st.toggle("Tester tous les types de d√©fauts",True)

        # 1er cas : on r√©cup√®re une image de chaque classe au hasard (=> 10 en tout)
        if all_classes:
            nb_img = y_test.nunique()
            index_sel = y_test.groupby(y_test).apply(lambda x: x.sample(1)).index.get_level_values(1)
        # 2√®me cas : l'utilisateur choisit la classe et le nb d'images de cette classe √† afficher
        else:
            sel_cols = st.columns(2)
            with sel_cols[0]:
                nom_classe = st.selectbox("Choix du d√©faut",y_test.unique())
            with sel_cols[1]:
                nb_img = st.slider("Nombre d'images √† afficher",1,10,5)
            # S√©curit√© : cas o√π nb d'√©l√©ments de la classe < nb demand√©
            nb_img = min(nb_img,len(y_test[y_test==nom_classe]))
            # On r√©cup√®re de mani√®re al√©atoire les images demand√©es
            index_sel = y_test.groupby(y_test[y_test==nom_classe]).apply(lambda x: x.sample(nb_img, replace=False)).index.get_level_values(1)
        
        # Bouton pour rafraichir => gr√¢ce au tirage al√©atoire, on affichera d'autres images avec les param√®tres s√©lectionn√©s
        if st.button("üîÑ Changer d'images"):
            pass

    # On r√©cup√®re les chemins et les labels des images s√©lectionn√©es
    sel_path = X_test.loc[index_sel,"Chemin"]
    sel_y_test = y_test[index_sel]
    
    st.markdown("""
    Pour chaque image, comparez les pr√©dictions de nos mod√®les : les erreurs apparaissent en rouge.
    """)

    # Ent√™tes de la grille de comparaison
    with st.container(border=True):
        cols = st.columns(len(modeles)+2)
        headers = ["Image", "D√©faut"] + [f"Pr√©diction {modele_name}" for modele_name in modeles]
        for c, h in zip(cols, headers):
            with c:
                st.html(f"<div style='text-align:center; font-weight:bold'>{h}</div>")

    # 1 ligne par image √† pr√©dire
    for i in range(nb_img):
        with st.container(border=True):
            cols = st.columns(len(modeles)+2) 
        
            # Colonne 0 : affiche de l'image
            # Artifice pour centrer horizontalement
            with cols[0]:
                left, mid, right = st.columns([1, 3, 1])
                with mid:
                    st.image(sel_path.iloc[i])
            
            # Col 1 : affichage du d√©faut r√©el
            with cols[1]:
                st.html(f"<div style='text-align:center; border:1px solid #eee; padding:2px';><b>{sel_y_test.iloc[i]}</b></div>")

            # Col 2...n : affichage du d√©faut pr√©dit pour chaque mod√®le
            for j, model_name in enumerate(modeles):
                pred = modeles[model_name]["predicted_data_test"][index_sel][i]
                color = "green" if pred == sel_y_test.iloc[i] else "red"
                with cols[j+2]:
                    st.html(f"<div style='text-align:center; border:1px solid #eee; padding:2px; color:{color}'><b>{pred}</b></div>")

def show_bilan():
    st.header("Bilan")
    st.write("TODO : conclusion sur meilleur mod√®le, conclusion m√©tier, critique, perspectives")

