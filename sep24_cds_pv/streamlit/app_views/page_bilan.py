import streamlit as st
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score


def show_bilan(modeles,y_test):

    st.header("Bilan",divider="gray")

    # CrÃ©ation des tabs
    tab1, tab2, tab3, tab4 = st.tabs(["Meilleur modÃ¨le", "Conclusions", "Critiques", "Perspectives"])
    
    # Tab 1 : Meilleur modÃ¨le
    with tab1:

        st.subheader(":red[MobileNetV2] (CNN prÃ©-entraÃ®nÃ©) :red[+ Transfer Learning]")
        st.markdown("""
            - **Meilleures performances** pour les mÃ©thodes **:red[Deep Learning]** basÃ©es sur des rÃ©seaux de neurones convolutionnels (CNN - Convolutional Neural Network)
            - **:red[MobileNetV2]** fine-tunÃ© par **:red[Transfer Learning]** atteint un **F1-macro de :red[91.3%]**
        """)

        # L'utilisateur choisit un modÃ¨le de rÃ©fÃ©rence
        modele_ref_name = st.selectbox("RÃ©fÃ©rence de comparaison", list(modeles.keys()), index=3)

        # RÃ©cupÃ©ration des prÃ©dictions du modÃ¨le de rÃ©fÃ©rence sur le jeu de test
        y_pred_ref = modeles[modele_ref_name]["predicted_data_test"]
        accu_ref = accuracy_score(y_test,y_pred_ref)
        f1_ref = f1_score(y_test,y_pred_ref,average="macro")
        prec_healthy_ref = precision_score(y_test, y_pred_ref, labels=["healthy panel"],average=None)[0]
        recall_healthy_ref = recall_score(y_test, y_pred_ref, labels=["healthy panel"],average=None)[0]

        # Nombre de colonnes
        nb_cols = 7

        # Ligne d'en-tÃªtes
        metrics = [
            "Accuracy", 
            "F1 macro", 
            "PrÃ©cision Healthy", 
            "Rappel Healthy",
        ]
        definitions = [
            "Pourcentage de bonnes prÃ©dictions, toutes classes confondues",
            "Moyenne arithmÃ©tique simple des F1-scores de toutes les classes",
            "Pourcentage de prÃ©dictions 'healthy' correctes parmi toutes les prÃ©dictions 'healthy' \n\nğŸ‘‰ PrÃ©cision 'healthy' faible -> on manque des dÃ©fauts",
            "Pourcentage de vrais 'healthy' dÃ©tectÃ©s parmi tous les individus rÃ©ellement 'healthy' \n\nğŸ‘‰ Rappel 'healthy' faible -> on dÃ©tecte des dÃ©fauts Ã  tort",
        ]
        cols = st.columns(nb_cols)
        for idx, col in enumerate(cols[2:-1]):
            with col:
                st.markdown(f":gray[{metrics[idx]}]", help=definitions[idx])

        # Pour chaque modÃ¨le
        metric_height = "stretch"
        for modele_name in modeles:
            # RÃ©cupÃ©ration des prÃ©dictions du modÃ¨le sur le jeu de test
            y_pred = modeles[modele_name]["predicted_data_test"]
            # Affichage cÃ´te Ã  cÃ´te des mÃ©triques principales et de leur diffÃ©rence avec les mÃ©triques de rÃ©fÃ©rence
            _, col1, col2, col3, col4, col5, _ = st.columns(nb_cols)
            with col1:
                st.markdown(f"**{modele_name}**")
            with col2:
                accu = accuracy_score(y_test,y_pred)
                st.metric("Accuracy", 
                          f"{accu*100:.1f} %", 
                          f"{(accu-accu_ref)*100:.1f} %" if modele_name!=modele_ref_name else None, 
                          height=metric_height,
                          label_visibility="collapsed")
            with col3:
                f1 = f1_score(y_test,y_pred,average="macro")
                st.metric("F1 macro", 
                          f"{f1*100:.1f} %", 
                          f"{(f1-f1_ref)*100:.1f} %" if modele_name!=modele_ref_name else None,
                          height=metric_height,
                          label_visibility="collapsed")
            with col4:
                prec_healthy = precision_score(y_test, y_pred, labels=["healthy panel"],average=None)[0]
                st.metric("PrÃ©cision Healthy", 
                          f"{prec_healthy*100:.1f} %", 
                          f"{(prec_healthy - prec_healthy_ref)*100:.1f} %" if modele_name!=modele_ref_name else None, 
                          height=metric_height,
                          label_visibility="collapsed")
            with col5:
                recall_healthy = recall_score(y_test, y_pred, labels=["healthy panel"],average=None)[0]
                st.metric("Rappel Healthy", 
                          f"{recall_healthy*100:.1f} %", 
                          f"{(recall_healthy - recall_healthy_ref)*100:.1f} %" if modele_name!=modele_ref_name else None, 
                          height=metric_height,
                          label_visibility="collapsed")
    
        with st.expander("Rappel de la dÃ©finition des diffÃ©rentes mÃ©triques"):

            col1, col2 = st.columns(2)
            with col1:
                st.subheader("Accuracy")
                st.markdown("""
                    Pourcentage de bonnes prÃ©dictions faites par le modÃ¨le, toutes classes confondues.
                """)
                st.latex(r"Accuracy = \frac{VP + VN}{VP + VN + FP + FN}")

            with col2:
                with st.columns([1,2,1])[1]:
                    st.text("")
                    st.text("")
                    st.markdown("""
                        - **VP** : Vrais positifs
                        - **VN** : Vrais NÃ©gatifs
                        - **FP** : Faux positifs
                        - **FN** : Faux nÃ©gatifs
                    """)

            col1, col2 = st.columns(2)
            with col1:
                st.subheader("PrÃ©cision")
                st.markdown("""
                    Pourcentage de prÃ©dictions positives correctes parmi toutes les prÃ©dictions positives faites par le modÃ¨le.
                """)
                st.latex(r"PrÃ©cision = \frac{VP}{VP + FP}")
                st.markdown("ğŸ‘‰ Parmi tous les individus identifiÃ©s comme positifs, combien sont vraiment positifs ?")

            with col2:
                st.subheader("Rappel")
                st.markdown("""
                    Pourcentage de vrais positifs dÃ©tectÃ©s parmi tous les individus rÃ©ellement positifs.
                """)
                st.latex(r"Rappel = \frac{VP}{VP + FN}")
                st.markdown("ğŸ‘‰ Parmi tous les individus rÃ©ellement positifs, quelle proportion le modÃ¨le a-t-il correctement dÃ©tectÃ©s ?")


    # Tab 2 : Conclusions
    with tab2:

        st.subheader("Conclusions sur le projet")
        st.markdown("""
            - Confirmation : **Deep Learning > Machine Learning** : CNN plus efficaces âœ…
            - **Objectif initial :red[dÃ©passÃ©]** : Ã©quipe PVF-10 :red[battue] ! ğŸ¯
                - **Equipe PVF-10** -> CoatNet (20.2M paramÃ¨tres) : Accuracy **93.3%** - F1 macro **88.7%**
                - **Equipe Datascientest** -> MobileNetV2 (3.5M paramÃ¨tres) : Accuracy **:red[94.2%]** - F1 macro **:red[91.3%]**
            - **Avantage DL**
                - ğŸ” **:red[Auto-sÃ©lection des features]** -> **le modÃ¨le "choisit" lui-mÃªme** les **features les plus pertinents :red[pendant l'apprentissage]**
            - **Avantage ML** : 
                - ğŸ§© **:red[Meilleure interprÃ©tabilitÃ©]** (dÃ©pend en rÃ©alitÃ© du **modÃ¨le utilisÃ©**)
                - ğŸª¶ **:red[ModÃ¨les plus lÃ©gers]** -> â±ï¸ **gain de temps** (apprentissage comme prÃ©diction - **mais l'extraction des features peut Ãªtre long**)
            - Choix **ML vs DL** : **compromis** entre
                - ğŸ“ˆ **:red[Performance de prÃ©diction]** (accuracy, prÃ©cision, rappel)
                - ğŸ–¥ï¸ **:red[Contraintes de dÃ©ploiement]** (moyens de calcul limitÃ©s - temps rÃ©el embarquÃ© par exemple)
        """)

#         """)

    # Tab 3 : Critiques
    with tab3:

        st.subheader("Regard critique sur notre travail")
        st.markdown("""
            - **ChaÃ®ne d'acquisition :red[non maÃ®trisÃ©e]**
                - ğŸ” Conversion images infrarouge -> niveau de gris :red[non documentÃ©e]
                - ğŸš« :red[DifficultÃ© de rÃ©utilisation] de notre modÃ¨le sur **autres jeux de donnÃ©es** ou **images brutes**
                - âœ… **MÃ©thodologie appliquÃ©e :red[reste pertinente] !**
            - **DÃ©sÃ©quilibre entre classes -> :red[impact sur les performances]** (notamment des modÃ¨les ML)
                - ğŸ“‰ **Gain limitÃ©** des approches testÃ©es de :red[sur-Ã©chantillonnage] ou d':red[augmentation de donnÃ©es]
                - ğŸš€ **Potentiel d'amÃ©lioration** possible par exploration d'approches plus Ã©laborÃ©es
            - **Marge de progression des modÃ¨les ML** -> :red[exploration de features complÃ©mentaires]
                - ğŸ¯ **Ciblage** de certaines zones des images (CaractÃ©ristiques [GLCM](https://en.wikipedia.org/wiki/Co-occurrence_matrix) ou **entropie** 
                ou **indicateurs statistiques :red[localisÃ©s]**)
                - ğŸŒ€ Autres descripteurs de **texture** ([Local Binary Patterns](https://en.wikipedia.org/wiki/Local_binary_patterns) par exemple) 
                ou **features de forme** des hot spots de l'image
                - **:red[Mais]** rapport **effort / gain en performance** :red[dÃ©favorable] pour les modÃ¨les **ML vs DL** âš ï¸
                    - Tout **nouveau feature** doit Ãªtre testÃ©, tunÃ©, validÃ©, ... -> :red[opÃ©rations chronophages]
                    - **Chaque ajout de feature** :red[complexifie] **le pipeline** de calcul et l'apprentissage
                    - Rappel : les **rÃ©seaux de neurones** :red[apprennent par eux-mÃªmes] **les features pertinents** pour le problÃ¨me soumis !
        """)

    # Tab 4 : Perspectives
    with tab4:
        st.subheader("Perspectives - comment passer Ã  l'industrialisation...")
        st.markdown("""
            - **Valider la :red[gÃ©nÃ©ralisation du modÃ¨le]**
                - ğŸ§ª Tester d'**autres jeux de donnÃ©es**
            - **ComplÃ©ter l':red[intÃ©gration opÃ©rationelle]**
                - âš™ï¸ **MaÃ®triser le prÃ©-processing** (images thermiques â†’ niveaux de gris)
                - ğŸ¯ Ajouter un **modÃ¨le de dÃ©tection** en amont (type [YOLO](https://en.wikipedia.org/wiki/You_Only_Look_Once)) -> :red[segmentation] des panneaux PV dans une image complÃ¨te
            - **Maintenir une :red[veille technologique]** sur nouveaux modÃ¨les ou architectures DL
                - ğŸ§  **Architectures plus rÃ©centes** : Transformers
                - ğŸ”€ **Hybrides** : Tranformers + CNN ou CNN + classifieurs ML
                - ğŸŒ¡ï¸ **SpÃ©cialisÃ©s** : modÃ¨les prÃ©-entraÃ®nÃ©s sur bases d'images thermiques
            - **AmÃ©liorer l':red[interprÃ©tabilitÃ©]** des modÃ¨les DL mis en oeuvre -> dÃ©veloppement d'un module d'explication
                - ğŸ” Analyse **Grad-CAM** + logique basÃ©e sur **extraction de features** (type hot spots)
                - **Objectif** : ğŸ¤ :red[Performance DL] + :red[explication mÃ©tier] comprÃ©hensible pour un opÃ©rateur terrain
            - Certainement beaucoup d'autres choses...
        """)
