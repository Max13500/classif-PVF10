import streamlit as st
from PIL import Image
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,classification_report, confusion_matrix

@st.cache_data
def load_image(path):
    return Image.open(path)

def show_presentation(df):
    # Titre
    st.html(
        """
        <div style="
            border: 2px solid #1ABC9C;   /* bordure turquoise */
            border-radius: 12px;         /* angles arrondis */
            padding: 20px;               /* espace autour du texte */
            text-align: center;          /* texte centr√© */
            box-shadow: 2px 2px 12px rgba(0,0,0,0.1);  /* l√©g√®re ombre */
        ">
            <h1 style="margin:0;font-size:48px">Classification de d√©fauts dans les panneaux photovolta√Øques</h1>
        </div>
        """)
    
    st.subheader("Le contexte")
    st.markdown("***TODO***")

    st.subheader("Les objectifs")
    st.markdown("***TODO***")

    st.subheader("Les donn√©es")
    st.markdown("***TODO***")
    
    # On r√©cup√®re au hasard une ligne du dataframe par classe
    df_sel = df.groupby("Classe").apply(lambda x: x.sample(1))

    st.markdown("""
    Voici un **premier aper√ßu** des images du dataset (une image par classe) :
    """)

    # Affichage de 10 images : 5 images sur 2 lignes, avec leur classe en titre
    with st.container(border=True):
        for i in range(0, 10, 5):
            cols = st.columns(5)
            for j, col in enumerate(cols):
                if i + j < len(df_sel):
                    col.image(df_sel["Chemin"].iloc[i + j], caption = df_sel["Classe"].iloc[i + j],use_container_width=True)
    
    # Bouton pour rafraichir => gr√¢ce au tirage al√©atoire, on affichera d'autres images avec les param√®tres s√©lectionn√©s
    if st.button("üîÑ Changer d'images"):
        pass

def show_dataviz(df,statistiques):
    st.header("DataViz",divider="gray")

    st.subheader("Analyse g√©n√©rale du dataset")

    # Description du dataset et nettoyage
    st.markdown("""
    Notre √©tude porte sur **5579 images de type PNG au format 110x60 r√©parties selon 10 classes de d√©fauts**.
    Nous avons proc√©d√© √† une analyse globale et un **nettoyage** de ce jeu de donn√©es :
    - suppression de 7 doublons d'images    
    - annotation de 4% des images qui ont une dimension r√©elle diff√©rente de 110x60 (images d'origine carr√©es => potentiellement mauvais d√©coupage ou resizing)
    - renommage des 10 classes pour plus de lisibilit√©
    """)

    # Affichage du dataframe des m√©tadonn√©es
    with st.expander("Pour visualiser le dataframe final contenant les m√©tadonn√©es..."):
        st.dataframe(df)
    
    st.subheader("Equilibre des classes")

    # Description de l'√©quilibre des classes
    st.markdown("""
    Notre jeu de donn√©es est r√©parti suivant dix cat√©gories : neuf types de d√©fauts diff√©rents et une classe repr√©sentant les panneaux sains (*healthy panel*).
    La r√©partition des classes est **l√©g√®rement d√©s√©quilibr√©e** :
    - la classe des panneaux sains repr√©sente un peu plus d'un quart des observations
    - les neuf classes de d√©fauts se partagent le reste de mani√®re relativement √©quitable
    - deux cat√©gories sont toutefois en retrait : Break et String short circuit.
    """)

    # Diagramme de r√©partition des classes
    col1, col2, col3 = st.columns([0.1, 0.8, 0.1]) 
    with col2:     
        fig = plt.figure()
        sns.countplot(y = df['Classe'],hue = df['Classe'],legend=False)
        plt.title("R√©partition des classes de d√©fauts",fontsize=12, fontweight='bold')
        plt.xlabel("Nombre d'images")
        plt.ylabel("Classe de d√©faut")
        sns.despine()
        st.pyplot(fig)

    st.subheader("Les pseudo-couleurs")

    # Description des canaux RGB
    st.markdown("""
    L'analyse des canaux RGB a montr√© une **composante rouge tr√®s √©lev√©e**, et une composante bleue faible, quel que soit le type de d√©faut observ√©.
                
    Pour vous en rendre compte, visualisez la r√©partition des intensit√©s dans les 3 canaux Rouge, Vert et Bleu pour l'ensemble des classes :
    """)    

    # Distribution des intensit√©s moyennes des canaux RGB
    # Afficher 2 classes en parall√®le
    rgb_cols = st.columns(2)
    for i,c in enumerate(rgb_cols):
        with c:
            fig = plt.figure()
            # L'utilisateur choisit la classe
            nom_classe = st.selectbox("Classe de d√©faut :" if i==0 else "Comparer avec :",df["Classe"].unique(),i,key=f"classe_rgb_{i}")
            # R√©cup√©ration des intensit√©s moyennes sur les 3 canaux R/G/B
            mean_colors = statistiques["Moyenne des canaux RGB"][nom_classe]
            # Cr√©ation du violinplot correspondant
            parts = plt.violinplot(np.array(mean_colors),showmedians=True)
            plt.ylim([0,255])
            plt.title(f"Distribution des canaux RVB",fontsize=14, fontweight='bold')
            plt.xticks([1, 2, 3],labels=["Rouge","Vert","Bleu"],fontsize=14)
            plt.ylabel("Intensit√©s moy (0-255)",fontsize=14)
            # Changer la couleur de chaque violon
            colors = ["red","green","blue"]
            for j, pc in enumerate(parts['bodies']):
                pc.set_facecolor(colors[j])
                pc.set_edgecolor('black')
            st.pyplot(fig)
    
    # Fin description des canaux RGB
    st.markdown("""            
    Les images thermiques infra-rouges sont en **fausses couleurs** (ou pseudo-couleurs) :
    chaque pixel encode en r√©alit√© une valeur de temp√©rature, et une palette de couleur adapt√©e (du type ‚Äúinferno‚Äù) est utilis√©e pour am√©liorer la perception √† l'oeil humain des variations de temp√©rature.
                
    Nous avons donc fait le choix de travailler sur les **images converties en niveaux de gris**.
    """)

    st.subheader("Les niveaux de gris")

    # Description des niveaux de gris
    st.markdown("""
    L'analyse de **la distribution des niveaux de gris a montr√© des sp√©cificit√©s** selon le type de d√©fauts.

    Vous pouvez observer pour chaque classe les histogrammes de 5 **indicateurs statistiques** des niveaux de gris :
    """)    

    # L'utilisateur choisit l'indicateur statistique
    indicateur = st.selectbox("Indicateur statistique",list(statistiques.keys())[1:6]) 
    # Afficher 2 classes en parall√®le
    ndg_cols = st.columns(2)
    for i,c in enumerate(ndg_cols):
        with c:
            fig = plt.figure()
            # L'utilisateur choisit la classe
            nom_classe = st.selectbox("Classe de d√©faut :" if i==0 else "Comparer avec :",df["Classe"].unique(),i,key=f"classe_ndg_{i}")
            # R√©cup√©ration de l'indicateur statistique demand√© sur les NDG
            statistique = statistiques[indicateur][nom_classe]
            # Afficher l'histogramme et la densit√© de probabilit√© de l'indicateur
            sns.histplot(statistique,bins=20,stat="density",kde=True,alpha=0.6)
            plt.xlabel(indicateur,fontsize=14)
            plt.ylabel("Densit√© de probabilit√©",fontsize=14)
            plt.title(f"Histogramme (avec densit√© KDE)",fontsize=14, fontweight='bold')
            st.pyplot(fig)

    # Fin description des niveaux de gris
    st.markdown("""
    Les diff√©rences sont en g√©n√©ral plus marqu√©es sur les indicateurs Max et Ecart-type.
    
    Nous avons compl√©t√© cette visualisation par des **tests statistiques** (Kruskal-Wallis + test post-hoc de Dunn-Bonferroni) qui ont montr√© que des classes sont significativement diff√©rentes l'une de l'autre selon les indicateurs observ√©s.
    """)    

    st.subheader("Les textures")

    # Description entropie et densit√© de contours
    st.markdown("""
    L'analyse de caract√©ristiques avanc√©es extraites des images a permis d'approfondir cette √©tude :
    - la **densit√© de contours** : proportion de contours dans l'image apr√®s application du filtre de Canny, indiquant des transitions abruptes.
    - l'**entropie** : quantifie la diversit√© ou le d√©sordre des niveaux de gris. Une entropie √©lev√©e traduit une texture complexe.

    Observez pour chaque classe les histogrammes de ces propri√©t√©s :
    """)

    # Propri√©t√©s de texture
    # L'utilisateur choisit la propri√©t√© de texture
    propriete = st.selectbox("Propri√©t√© texturale",list(statistiques.keys())[6:8]) 
    # Afficher 2 classes en parall√®le
    prop_cols = st.columns(2)
    for i,c in enumerate(prop_cols):
        with c:
            fig = plt.figure()
            # L'utilisateur choisit la classe
            nom_classe = st.selectbox("Classe de d√©faut :" if i==0 else "Comparer avec :",df["Classe"].unique(),i,key=f"classe_prop_{i}")
            # R√©cup√©ration de la propri√©t√© demand√©e
            statistique = statistiques[propriete][nom_classe]
            # Afficher l'histogramme et la densit√© de probabilit√© de la propri√©t√©
            sns.histplot(statistique,bins=20,stat="density",kde=True,alpha=0.6)
            plt.xlabel(propriete,fontsize=14)
            plt.ylabel("Densit√© de probabilit√©",fontsize=14)
            plt.title(f"Histogramme (avec densit√© KDE)",fontsize=14, fontweight='bold')
            st.pyplot(fig)
    
    # Description propri√©t√©s GLCM
    st.markdown("""
    Nous avons √©galement calcul√© la matrice [GLCM](https://en.wikipedia.org/wiki/Co-occurrence_matrix) de chaque image.
    La Gray Level Co-occurrence Matrix mesure la fr√©quence de co-occurrence de paires de niveaux de gris √† une certaine distance et orientation.
    Nous pouvons en extraire les propri√©t√©s suivantes :
    - le **contraste** : mesure l'intensit√© des variations locales. Un contraste √©lev√© indique une texture avec de fortes diff√©rences de niveaux de gris.
    - l'**√©nergie** : plus l'√©nergie est grande, plus la texture est uniforme et r√©p√©titive.
    - l'**homog√©n√©it√©** : refl√®te la similarit√© entre pixels voisins. Une forte homog√©n√©it√© indique une texture lisse.
    - la **corr√©lation** : mesure la d√©pendance lin√©aire entre pixels voisins. Une forte corr√©lation indique une structure r√©guli√®re.

    Voici les valeurs moyennes de ces propri√©t√©s observ√©es pour chaque classe :
    """)
    
    # Histogrammes GLCM
    propriete_glcm = st.selectbox("Propri√©t√© GLCM",["Contraste","Correlation","Energie","Homogeneite"]) 
    col1, col2, col3 = st.columns([0.1, 0.8, 0.1]) 
    with col2:  
        st.image(
            load_image(f"resources/histo_{propriete_glcm.lower()}.png"),
            use_container_width=True
        )
    
    # Fin description textures
    st.markdown("""
    Concernant les textures, les propri√©t√©s de Contraste et de Densit√© de contours semblent avoir un pouvoir discriminant plus marqu√© en g√©n√©ral.
    
    Nous avons compl√©t√© cette visualisation par des **tests statistiques** (Kruskal-Wallis + test post-hoc de Dunn-Bonferroni).
    Ils nous ont montr√© que des classes sont significativement diff√©rentes l'une de l'autre selon les propri√©t√©s texturales observ√©es.
    """)  

def show_method():
    st.header("M√©thode",divider="gray")

    st.subheader(f"Machine Learning et Deep Learning")

    # Description des approches
    st.markdown("""
    Quatre approches ont √©t√© exp√©riment√©es :

    - **Approche Machine Learning classique** exploitant des **features *localis√©s*** (ex : pixels bruts...)  
    - **Approche Machine Learning classique** exploitant uniquement des **features *non localis√©s*** (ex : contraste...)  
    - **Approche Deep Learning** exploitant les images avec des r√©seaux de neurones convolutionnels *maison*  
    - **Approche Transfer Learning** exploitant les images avec des mod√®les pr√©-entra√Æn√©s  
    """)

    # Description des features localis√©s
    with st.expander("Pour en savoir plus sur les features localis√©s"):
        st.markdown("""
                    Ces descripteurs conservent une information de position ou de structure dans l'image. Nous avons extrait pour chaque image :
                    - Le **vecteur de pixels bruts** : les images sont d'abord redimensionn√©es (de 60x110 √† 30x55 pixels par exemple), puis leurs pixels sont lin√©aris√©s sous forme de vecteur 1D. Chaque pixel, codant une valeur de temp√©rature (niveau de gris), est alors une feature.
                    - Le **descripteur HOG** ([Histogram of Oriented Gradients](https://towardsdatascience.com/histogram-of-oriented-gradients-hog-in-computer-vision-a2ec66f6e671/?source=rss----7f60cf5620c9---4)) :
                    on d√©coupe l'image en cellules et on y calcule des histogrammes d'orientations de gradient, puis on normalise ces histogrammes. Le vecteur HOG r√©sultant capture les formes et structures pr√©sentes dans l'image.
                    """)
        st.image(load_image("resources/features_hog.png"),caption = "Exemples de descripteurs HOG (repr√©sentation 2D) pour quelques images")

    # Description des features non localis√©s
    with st.expander("Pour en savoir plus sur les features non localis√©s"):
        st.markdown("""
                    Ces descripteurs sont calcul√©s sur l'image enti√®re, sans consid√©ration explicite de la position spatiale. Nous avons extrait pour chaque image :
                    - des **statistiques sur les intensit√©s** (niveaux de gris de l'image) : moyenne, m√©diane, minimum, maximum, √©cart-type, quantiles (p5, p10, ‚Ä¶, p95) et histogramme sur 256 bins (0 √† 255).
                    - des **propri√©t√©s extraites de la matrice GLCM** : contraste, √©nergie, homog√©n√©it√©, corr√©lation
                    - des **statistiques sur la carte d'entropie** : moyenne, √©cart-type, histogramme d'entropie, etc. pour caract√©riser la complexit√© de l'image.
                    - la **densit√© de contours** d√©tect√©s dans l'image : pourcentage calcul√© apr√®s application d'un filtre de Canny.
                    - des **statistiques sur les ‚Äúhot spots‚Äù** : ce sont des r√©gions anormalement chaudes dans le panneau. Nous utilisons un seuillage adaptatif pour les d√©tecter et nous en extrayons des statistiques...
                    """)
        st.image(load_image("resources/features_entropy_canny.png"),caption = "Exemples de cartes d'entropie et contours d√©tect√©s pour quelques images")
    
    st.subheader(f"A la recherche du meilleur mod√®le...")

    # Un onglet M√©thodologie ML / Un onglet M√©thodologie DL
    tab1, tab2 = st.tabs(["Approches Machine Learning", "Approches Deep Learning"])
    with tab1:
        st.markdown("""
        Nous avons entra√Æn√© plusieurs **classifieurs** :
        - bas√©s sur les distances (SVM...)
        - bas√©s sur les arbres de d√©cision (Random Forest, XGBoost, LightGBM...)
        - √©galement un r√©seau de neurones dense
                    
        Nous avons mis en oeuvre une **validation crois√©e** avec grille de param√®tres pour optimiser notre pipeline :
        - d√©termination des **meilleures √©tapes de pr√©traitement** : extraction de features, mise √† l'√©chelle, r√©duction de dimensions, r√©√©chantillonnage‚Ä¶  
        - optimisation des **param√®tres internes des √©tapes** (ex. extraction de features : taille des cellules HOG)  
        - optimisation des **hyperparam√®tres des classifieurs** (ex. SVM : param√®tre de r√©gularisation `C`)  
        """)
    with tab2:
        st.markdown("""
        Nous avons test√© un r√©seau de neurones convolutif *maison*, et 2 mod√®les pr√©entra√Æn√©s sur ImageNet : MobileNetV2 et EfficientNetV2B2.
        Pour l'**entra√Ænement**, nous avons utilis√© :
        - la fonction de perte `sparse_categorical_crossentropy` adapt√©e aux probl√®mes multi-classes
        - l'optimiseur Adam pour la descente de gradient.
        - des callbacks pour √©viter le sur-apprentissage (`EarlyStopping` et `ReduceLROnPlateau` en cas de plafonnement des performances).
                    
        Nous avons mis en oeuvre une **validation fixe** avec grille de param√®tres pour optimiser notre r√©seau :
        - activation ou non de **couches d'augmentation de donn√©es** (ex : `RandomFlip`, `RandomContrast`)  
        - recherche d'une configuration optimale pour les **couches d'extraction de features** (ex : nb de filtres de convolution par couche)  
        - recherche d'une configuration optimale pour les **couches de classification** (ex : nb de couches `Dense`)  
        - optimisation de la **profondeur du d√©gel** dans le cas du Transfer Learning  
        """)
    
    # Description des m√©triques
    st.markdown("""
    Voici les principales **m√©triques** observ√©es : 
    - le F1-score macro (moyenne sur les 10 classes) : bon compromis pour √©valuer les performances globales dans un jeu d√©s√©quilibr√©.
    - l'accuracy
    - les temps d'entra√Ænement et de pr√©diction
    - la pr√©cision et le rappel de la classe *healthy* : capacit√© √† distinguer les panneaux sains des panneaux d√©fectueux  
    """)

def show_results(modeles,y_test):
    st.header("R√©sultats",divider="gray")

    st.markdown("""
    Nous pr√©sentons les meilleurs mod√®les obtenus apr√®s optimisation, pour les 4 approches mentionn√©es.
    """)

    # Choix du mod√®le par l'utilisateur  
    modele_name = st.selectbox(
        "Choix du mod√®le",
        list(modeles.keys()),
        format_func=lambda name: f"{modeles[name]['methodo_name']} : mod√®le {name}"
    )

    st.subheader(f"Architecture du mod√®le {modele_name}")

    # Description de l'architecture du mod√®le
    if modele_name == "SVM":
        st.markdown("""
                    Les meilleurs r√©sultats de l'approche ML avec features localis√©s ont √©t√© obtenus avec le classifieur SVM (noyau rbf) apr√®s ces √©tapes de preprocessing :
                    - extraction de features : vecteur de pixels bruts + descripteur HOG + statistiques d'entropie
                    - normalisation Min-Max
                    - r√©duction de dimensions par PCA conservant 90% de la variance
                    """)
    if modele_name == "XGBoost":
        st.markdown("""
                    Les meilleurs r√©sultats de l'approche ML avec features non localis√©s ont √©t√© obtenus avec le classifieur XGBoost apr√®s extraction des features,
                    sans √©tape de preprocessing suppl√©mentaire : statistiques sur les intensit√©s + propri√©t√©s extraites de GLCM + statistiques d'entropie + densit√© de contours
                    """)
    if modele_name == "CNN Perso":
        st.markdown("""
                    Les meilleurs r√©sultats de l'approche Deep Learning ont √©t√© obtenus avec ce r√©seau de neurones :
                    - couches d'augmentation de donn√©es actives : `RandomFlip`, `RandomBrightness`, `RandomContrast` et `GaussianNoise`
                    - normalisation des niveaux de gris par `Rescaling`
                    - 4 blocs convolutionels pour l'extraction de features compos√©s chacun de : `Conv2D` avec activation ReLU, puis `MaxPooling2D` pour r√©duire la taille, et un `Dropout` afin de r√©gulariser 
                    - passage en 1D : simple `Flatten`
                    - pour la classification : 2 couches `Dense` 
                    """)
    if modele_name == "MobileNet":
        st.markdown("""
                    Les meilleurs r√©sultats de l'approche Transfer Learning ont √©t√© obtenus avec un fine-tuning du mod√®le pr√©-entra√Æn√© MobileNetV2 :
                    - couches d'augmentation de donn√©es actives : `RandomFlip`, `RandomBrightness`, `RandomContrast` et `GaussianNoise`
                    - couches d'extraction de features : backbone MobileNet, avec un d√©gel des poids √† partir du 5√®me bloc
                    - passage en 1D par `GlobalAveragePooling2D`
                    - pour la classification : une couche `Dense` puis une r√©gularisation `Dropout`, et une derni√®re couche `Dense`
                    """)

    st.subheader(f"Performances du mod√®le {modele_name}")

    # R√©cup√©ration des pr√©dictions du mod√®le sur le jeu de test
    y_pred = modeles[modele_name]["predicted_data_test"]

    # Affichage c√¥te √† c√¥te des m√©triques principales
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Accuracy", round(accuracy_score(y_test,y_pred), 3))
    with col2:
        st.metric("F1 macro", round(f1_score(y_test,y_pred,average="macro"), 3))
    with col3:
        st.metric("Pr√©cision Healthy", round(precision_score(y_test, y_pred, labels=["healthy panel"],average=None)[0], 3))
    with col4:
        st.metric("Rappel Healthy", round(recall_score(y_test, y_pred, labels=["healthy panel"],average=None)[0], 3))

    # Choix par l'utilisateur entre rapport de classification et matrice de confusion
    display = st.radio('Que souhaitez-vous afficher ?', ('Rapport de classification', 'Matrice de confusion'))

    # Affichage rapport de classification
    if display == 'Rapport de classification':
        report_dict = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report_dict).transpose()
        # M√©triques par classe
        st.table(report_df.iloc[:-3,:].style.format(precision=2))
        # M√©triques globales
        st.table(report_df.iloc[-2:,:].style.format(precision=2))

    # Affichage matrice de confusion
    elif display == 'Matrice de confusion':
        cm = confusion_matrix(y_test, y_pred)
        fig = plt.figure()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
        plt.xlabel("Pr√©dictions")
        plt.ylabel("Vraies classes")
        st.pyplot(fig)
    
    st.subheader(f"Interpr√©tabilit√© du mod√®le {modele_name}")

    # Description de l'interpr√©tabilit√© du mod√®le
    if modele_name == "SVM":
        st.markdown("""
                    Le classifieur SVM, qui repose sur un noyau non lin√©aire et pr√©c√©d√© d'une PCA, n'est pas facilement interpr√©table.
                    Nous avons utilis√© **LIME** qui reste une m√©thode approximative et locale.

                    Dans cet exemple, on note que le mod√®le a bien fait le focus sur la bande de salissure situ√©e en haut pour classifier l'image Bottom Dirt. 
                    """)
        st.image(load_image("resources/interpretabilite_svm.png"),caption="Interpr√©tabilit√© LIME sur une image Bottom Dirt")
    if modele_name == "XGBoost":
        st.markdown("""
                    Nous pouvons faire ici une interpr√©tabilit√© assez directe, √† la fois globale et locale, √† l'aide de :
                    - la simplicit√© relative des features et de la pipeline
                    - l'**importance des features** fournie intrins√®quement par XGBoost
                    - l'utilisation de **SHAP**

                    Par exemple avec SHAP, nous pouvons voir les caract√©ristiques les plus influentes pour la classification :
                    - la valeur max des pixels de l'image. Notamment pour les classes healthy et break (qui doit √™tre peu √©lev√©e pour la premi√®re, tr√®s √©lev√©e pour la seconde)
                    - la densit√© de contours
                    - le degr√© de dissym√©trie de la distribution des niveaux de gris
                    - les propri√©t√©s de texture en g√©n√©ral
                    """)
        st.image(load_image("resources/interpretabilite_xgboost.png"),caption="Interpr√©tabilit√© SHAP globale")
    if modele_name == "CNN Perso":
        st.markdown("""
                    Nous avons appliqu√© la technique de **Grad-CAM** sur les couches de convolution de ce CNN pour visualiser les zones des images les plus d√©terminantes dans la d√©cision.
                    D'apr√®s les exemples d'images √©tudi√©s, le CNN a bien appris √† rep√©rer les zones chaudes, les patterns de salissure en bas, etc., concordant avec l'expertise m√©tier.
                    Nous avons √©galement utilis√© **SHAP** en compl√©ment, qui a confirm√© la coh√©rence des principales zones observ√©es par le mod√®le pour la pr√©diction des d√©fauts.

                    Dans l'exemple ci-dessous, une image pr√©dite Short circuit panel, la Grad-CAM met en √©vidence les cellules avec des grosses variations de temp√©rature d√®s la seconde couche de convolution.
                    """)
        st.image(load_image("resources/interpretabilite_cnn.png"),caption="Grad-CAM appliqu√© aux 4 couches de convolution sur une image Short circuit panel")
    if modele_name == "MobileNet":
        st.markdown("""
                    Nous avons appliqu√© **SHAP** sur les images des diff√©rentes cat√©gories pour comprendre sur quelles r√©gions notre mod√®le se focalise pour telle ou telle pr√©diction.
                    Sur quelques images test, SHAP a pu mettre en √©vidence les zones chaudes ou anormales du panneau comme ayant les valeurs SHAP les plus √©lev√©es pour pr√©dire la classe correspondante.
                    En d'autres termes, le mod√®le MobileNet fine-tun√© utilise bien les hot spots ou motifs de panne attendus.

                    Par exemple sur l'image Hot Cell ci-dessous, on constate que les cellules avec une forte variation locale de temp√©rature √† droite ont bien √©t√© rep√©r√©es.
                    """)
        st.image(load_image("resources/interpretabilite_mobilenet.png"),caption="Interpr√©tabilit√© SHAP sur une image Hot Cell")


def show_demo(modeles,X_test,y_test):
    st.header("D√©mo",divider="gray")

    st.markdown("""
                Choisissez des images de test : vous pouvez afficher tous les types de d√©fauts, ou vous concentrer sur un d√©faut en particulier.

                Remarque : ces images n'ont pas √©t√© utilis√©es lors de l'entra√Ænement des mod√®les.
    """)

    with st.container(border=True):
        # Choix par l'utilisateur d'afficher une image de chaque classe, ou une classe en particulier
        all_classes = st.toggle("Tester tous les types de d√©fauts",True)

        # 1er cas : on r√©cup√®re une image de chaque classe au hasard (=> 10 en tout)
        if all_classes:
            nb_img = y_test.nunique()
            index_sel = y_test.groupby(y_test).apply(lambda x: x.sample(1)).index.get_level_values(1)
        # 2√®me cas : l'utilisateur choisit la classe et le nb d'images de cette classe √† afficher
        else:
            sel_cols = st.columns(2)
            with sel_cols[0]:
                nom_classe = st.selectbox("Choix du d√©faut",y_test.unique())
            with sel_cols[1]:
                nb_img = st.slider("Nombre d'images √† afficher",1,10,5)
            # S√©curit√© : cas o√π nb d'√©l√©ments de la classe < nb demand√©
            nb_img = min(nb_img,len(y_test[y_test==nom_classe]))
            # On r√©cup√®re de mani√®re al√©atoire les images demand√©es
            index_sel = y_test.groupby(y_test[y_test==nom_classe]).apply(lambda x: x.sample(nb_img, replace=False)).index.get_level_values(1)
        
        # Bouton pour rafraichir => gr√¢ce au tirage al√©atoire, on affichera d'autres images avec les param√®tres s√©lectionn√©s
        if st.button("üîÑ Changer d'images"):
            pass

    # On r√©cup√®re les chemins et les labels des images s√©lectionn√©es
    sel_path = X_test.loc[index_sel,"Chemin"]
    sel_y_test = y_test[index_sel]
    
    st.markdown("""
    Pour chaque image, **comparez les pr√©dictions de nos mod√®les** : les erreurs apparaissent en rouge.
    """)

    # Ent√™tes de la grille de comparaison
    with st.container(border=True):
        cols = st.columns(len(modeles)+2)
        headers = ["Image", "D√©faut"] + [f"Pr√©diction {modele_name}" for modele_name in modeles]
        for c, h in zip(cols, headers):
            with c:
                st.html(f"<div style='text-align:center; font-weight:bold'>{h}</div>")

    # 1 ligne par image √† pr√©dire
    for i in range(nb_img):
        with st.container(border=True):
            cols = st.columns(len(modeles)+2) 
        
            # Colonne 0 : affiche de l'image
            # Artifice pour centrer horizontalement
            with cols[0]:
                left, mid, right = st.columns([1, 3, 1])
                with mid:
                    st.image(sel_path.iloc[i])
            
            # Col 1 : affichage du d√©faut r√©el
            with cols[1]:
                st.html(f"<div style='text-align:center; border:1px solid #eee; padding:2px';><b>{sel_y_test.iloc[i]}</b></div>")

            # Col 2...n : affichage du d√©faut pr√©dit pour chaque mod√®le
            for j, model_name in enumerate(modeles):
                pred = modeles[model_name]["predicted_data_test"][index_sel][i]
                color = "green" if pred == sel_y_test.iloc[i] else "red"
                with cols[j+2]:
                    st.html(f"<div style='text-align:center; border:1px solid #eee; padding:2px; color:{color}'><b>{pred}</b></div>")

def show_bilan(modeles,y_test):
    st.header("Bilan",divider="gray")

    st.subheader(f"Le Transfer Learning en t√™te")
    st.markdown("***TODO***")

    # L'utilisateur choisit un mod√®le de r√©f√©rence
    modele_ref_name = st.selectbox("R√©f√©rence de comparaison",list(modeles.keys()))

    # R√©cup√©ration des pr√©dictions du mod√®le de r√©f√©rence sur le jeu de test
    y_pred_ref = modeles[modele_ref_name]["predicted_data_test"]
    accu_ref = accuracy_score(y_test,y_pred_ref)
    f1_ref = f1_score(y_test,y_pred_ref,average="macro")
    prec_healthy_ref = precision_score(y_test, y_pred_ref, labels=["healthy panel"],average=None)[0]
    recall_healthy_ref = recall_score(y_test, y_pred_ref, labels=["healthy panel"],average=None)[0]

    # Pour chaque mod√®le
    for modele_name in modeles:
        # R√©cup√©ration des pr√©dictions du mod√®le sur le jeu de test
        y_pred = modeles[modele_name]["predicted_data_test"]
        # Affichage c√¥te √† c√¥te des m√©triques principales et de leur diff√©rence avec les m√©triques de r√©f√©rence
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.markdown(f"**{modele_name} :**")
        with col2:
            accu = accuracy_score(y_test,y_pred)
            st.metric("Accuracy", f"{accu*100:.1f} %", f"{(accu-accu_ref)*100:.1f} %" if modele_name!=modele_ref_name else None)
        with col3:
            f1 = f1_score(y_test,y_pred,average="macro")
            st.metric("F1 macro", f"{f1*100:.1f} %", f"{(f1-f1_ref)*100:.1f} %" if modele_name!=modele_ref_name else None)
        with col4:
            prec_healthy = precision_score(y_test, y_pred, labels=["healthy panel"],average=None)[0]
            st.metric("Pr√©cision Healthy", f"{prec_healthy*100:.1f} %", f"{(prec_healthy - prec_healthy_ref)*100:.1f} %" if modele_name!=modele_ref_name else None)
        with col5:
            recall_healthy = recall_score(y_test, y_pred, labels=["healthy panel"],average=None)[0]
            st.metric("Rappel Healthy", f"{recall_healthy*100:.1f} %", f"{(recall_healthy - recall_healthy_ref)*100:.1f} %" if modele_name!=modele_ref_name else None)
    
    st.subheader("Conclusion")
    st.markdown("***TODO : conclusion m√©tier, regard critique***")

    st.subheader("Perspectives")
    st.markdown("***TODO***")


